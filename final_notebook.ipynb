{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neutral Review Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consumer reviews has historically been one of the best ways for business owners to understand more fully the needs and wants of their consumers, thus being an important tool for businesses to leverage in order to create a complete and enjoyable experience that encompasses their consuemr base. One important tool for this is business intelligence. However, business intelligence suites are generally expensive and inflexible, making it difficult for smaller businesses that are not largely scaled to gain a sufficient amount of value from these business suites to justify spending the amount it costs to utilize them. Thus, I wanted to create a business intelligence tool that could add value to consumer reviews that may not seem informationally valuable at first glance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Neutral Feedback Problem: \n",
    "Generally speaking, 4 and 5 star reviews are positive consumer experiences, and the language in these reviews reflect that with highlights and recommendations to others. On the other end of the spectrum, 1 and 2 star reviews are generally negative consumer experiences, and the language in these reviews are facets of the experience that consumers think should be improved. This can more easily be thought of as: 4-5 star reviews - highlights, and 1-2 star reviews - improvements needed. However, in the middle ground, a place of difficult interpretability, are the neutral 3 star reviews. These reviews typically have a middle ground between \"highlights\" and \"improvements needed\", thus making it difficult to quickly glean any information, unless a human manually goes through and classifies the language in the context of the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to add informational value to the difficult-to-interpret reviews by classifying them as positive or negative, hopefully offering a quick way for small business owners to gain value from these neutral reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, f1_score\n",
    "import string\n",
    "import pickle\n",
    "import spacy\n",
    "from nltk.util import ngrams\n",
    "import nltk, re, string, collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/smaller/yelp_review.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['stars'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some EDA and visualizations here to give us a better idea of the data we're working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import list of stopwords from SpaCy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to tokenize the text of the articles\n",
    "punctuation = [*string.punctuation , *[str(x) for x in list(range(0,10))]]\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def normalize(text):\n",
    "    text = ''.join([x for x in text if x not in punctuation])\n",
    "    toks = nlp(text)\n",
    "    toks = [word.lemma_.lower().strip() for word in toks if word.pos_ != 'PRON']\n",
    "    toks = [word for word in toks if word not in stop_words]\n",
    "    return ' '.join(toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda = df.sample(500000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tokenization function to the real articles. Create a new column for the processed articles\n",
    "eda['processed_articles'] = eda['text'].map(lambda x: normalize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_text = eda.processed_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pickle/true_text'\n",
    "pickle.dump(true_text, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_text = pickle.load(open('pickle/true_text', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all of the tokenized words\n",
    "true_list = []\n",
    "for x in true_text:\n",
    "    true_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud().generate(str(true_list))\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize = (15, 15))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('images/wordcloud.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list of stopwords\n",
    "stopwords = ['m', 've', 'nt', '``', 's', 'c', \"'\", \",\", \"t\", \"l\", 'j', '...', \":\", '0', '1', '2', 'couldn', 'wouldn', 'isn', 'aren', 'shouldn', 'don', 'doesn', 'didn']\n",
    "# Create a new tokenized list to use in the frequency distribution tables\n",
    "true_tokenized_word = nltk.word_tokenize(str(true_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through new tokenized list and remove additional stopwords.\n",
    "true_tokenized_word = [word for word in true_tokenized_word if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create frequency distribution for the words in the real articles\n",
    "true_fdist=nltk.FreqDist(true_tokenized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_fdist.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frequency distribution for the 20 most common words\n",
    "true_fdist.plot(20)\n",
    "plt.savefig('images/freq_dist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the bi-grams\n",
    "true_bigrams = ngrams(true_tokenized_word, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List 20 most common bigrams\n",
    "true_bigrams_freq = collections.Counter(true_bigrams)\n",
    "true_bigrams_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_bigram_fdist=nltk.FreqDist(true_bigrams_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_bigram_fdist.plot(20)\n",
    "plt.savefig('images/bigram_freq.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Star Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(eda['stars'].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings distribution\n",
    "fig, ax = plt.subplots(figsize = (14,8))\n",
    "plt.bar(eda[\"stars\"].value_counts().keys(), eda['stars'].value_counts().values)\n",
    "ax.set_xlabel('Star Ratings')\n",
    "ax.set_ylabel('Number of Ratings')\n",
    "ax.set_title('Class Distribution')\n",
    "\n",
    "plt.savefig('images/stars_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Neutral Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because neutral reviews aren't classified as positive or negative at this point, we can't train the model on them. We will drop the 3 star reviews for now, then manually classify them in a different dataset, at which point we will add them back into this training set with a holdout for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['stars'] == 3].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding in Manually Classified Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated above, this dataset is the 3 star reviews that were removed for the sake of training. This section adds them back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_classified = pd.read_csv('data/manual_classified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_classified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the training portion of the manually classified dataset\n",
    "manual_training = manual_classified.sample(150, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the testing set of the manual classified dataset\n",
    "manual_test = manual_classified[~manual_classified.index.isin(manual_training.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['stars'] > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, f1_score\n",
    "import string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because of computational power, we limit the training and testing sample to 500,000 entries\n",
    "sample = df.sample(500000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ensure that we have the neutral reviews in here, we append them manually\n",
    "sample = sample.append(manual_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = sample['text']\n",
    "y = sample['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer (not used in final results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X_t_vec = cv.fit_transform(X_train)\n",
    "X_t_vec  = pd.DataFrame.sparse.from_spmatrix(X_t_vec)\n",
    "X_t_vec.columns = sorted(cv.vocabulary_)\n",
    "X_t_vec.set_index(y_train.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_vec = cv.transform(X_test)\n",
    "X_val_vec  = pd.DataFrame.sparse.from_spmatrix(X_val_vec)\n",
    "X_val_vec.columns = sorted(cv.vocabulary_)\n",
    "# X_val_vec.set_index(y_train.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb.fit(X_t_vec, y_train)\n",
    "y_hat = mnb.predict(X_val_vec)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords_list = stopwords.words('english') + list(string.punctuation)\n",
    "stopwords_list += [\"''\", '\"\"', '...', '``', '-', \"'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for removing stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def process_article(article):\n",
    "    tokens = nltk.word_tokenize(article)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token.lower() not in stopwords_list]\n",
    "    return stopwords_removed    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping funtion to X_train and X_test\n",
    "\n",
    "processed_X_t = list(map(process_article, X_train))\n",
    "\n",
    "processed_X_val = list(map(process_article, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RegEx \n",
    "## to get everything between square brackets: r'[[].*?[]]'\n",
    "## to get everything that starts with a capital letter: r'[[][A-Z].*?[]]''\n",
    "## to get everything that starts with a capital letter and no white space: r'[[][A-Z][a-z]*?[]]'\n",
    "\n",
    "regex_person_reg = r\"([A-Z][a-z].*?[^\\s]*)\\:\"\n",
    "regex_person_upper = r\"([A-Z][^\\s]*)\\:\"\n",
    "regex_parens = r'[[][A-Z].*?[]]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_data_train = vectorizer.fit_transform(X_train, y_train)\n",
    "tf_idf_data_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle vectorizer\n",
    "\n",
    "filename = 'pickle/tfidf_vectorizer'\n",
    "pickle.dump(vectorizer, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vectorizer\n",
    "\n",
    "nb_train_preds = pickle.load(open('pickle/tfidf_vectorizer', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Modeling - NB and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier.fit(tf_idf_data_train, y_train)\n",
    "nb_train_preds = nb_classifier.predict(tf_idf_data_train)\n",
    "nb_test_preds = nb_classifier.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(tf_idf_data_train, y_train)\n",
    "rf_train_preds = rf_classifier.predict(tf_idf_data_train)\n",
    "rf_test_preds = rf_classifier.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle Predictions - NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# pickle Naive Bayes Classifier\n",
    "\n",
    "filename = 'pickle/nb_classifier'\n",
    "pickle.dump(nb_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle Naive Bayes Classifier train predictions\n",
    "\n",
    "filename = 'pickle/nb_train_preds'\n",
    "pickle.dump(nb_train_preds, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle Naive Bayes Classifier test predictions\n",
    "\n",
    "filename = 'pickle/nb_test_preds'\n",
    "pickle.dump(nb_test_preds, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle Preds - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle Random Forest Classifier\n",
    "\n",
    "filename = 'pickle/rf_classifier'\n",
    "pickle.dump(rf_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle Random Forest Classifier train predictions\n",
    "\n",
    "filename = 'pickle/rf_train_preds'\n",
    "pickle.dump(rf_train_preds, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle Random Forest Classifier test predictions\n",
    "\n",
    "filename = 'pickle/rf_test_preds'\n",
    "pickle.dump(rf_test_preds, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load nb train preds\n",
    "\n",
    "nb_train_preds = pickle.load(open('pickle/nb_train_preds', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nb test preds\n",
    "\n",
    "nb_test_preds = pickle.load(open('pickle/nb_test_preds', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load rf train preds\n",
    "\n",
    "rf_train_preds = pickle.load(open('pickle/rf_train_preds', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nb test preds\n",
    "\n",
    "rf_test_preds = pickle.load(open('pickle/rf_test_preds', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_score = f1_score(y_train, nb_train_preds)\n",
    "nb_test_score = f1_score(y_test, nb_test_preds)\n",
    "rf_train_score = f1_score(y_train, rf_train_preds)\n",
    "rf_test_score = f1_score(y_test, rf_test_preds)\n",
    "\n",
    "print(\"Multinomial Naive Bayes\")\n",
    "print(\"Training F1: {:.4} \\t\\t\".format(nb_train_score))\n",
    "print(\"\")\n",
    "print(\"Test F1: {:.4} \\t\\t\".format(nb_test_score))\n",
    "print('-'*70)\n",
    "print(\"\")\n",
    "print('Random Forest')\n",
    "print(\"Training F1: {:.4} \\t\\t\".format(rf_train_score))\n",
    "print(\"\")\n",
    "print(\"Test F1: {:.4} \\t\\t\".format(nb_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB and RF Modeling Review\n",
    "Based on what we see here, these models both seem pretty good! A relatively steep drop off from the training score and the testing score is somwhat concerning on the Random Forest model, though. Could be overfit.\n",
    "\n",
    "One thing about the metric we're using, F1: I thought that the F1 score would be pretty relevant because we aren't too concerned about false positives and false negatives, like we would be if we were predicting the chance of a disease or something like that. We do have somewhat of a class imbalance as well, with much more of the positive reviews than the negative reviews. Thus, F1 score is a decent metric to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter = 500)\n",
    "lr.fit(tf_idf_data_train, y_train)\n",
    "lr_train_preds = lr.predict(tf_idf_data_train)\n",
    "lr_test_preds = lr.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle lr model and predictions\n",
    "\n",
    "filename = 'pickle/lr_classifier'\n",
    "pickle.dump(lr, open(filename, 'wb'))\n",
    "\n",
    "filename = 'pickle/lr_train_preds'\n",
    "pickle.dump(lr_train_preds, open(filename, 'wb'))\n",
    "\n",
    "filename = 'pickle/lr_test_preds'\n",
    "pickle.dump(lr_test_preds, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load LR Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lr pickle\n",
    "\n",
    "lr_train_preds = pickle.load(open('pickle/lr_train_preds', 'rb'))\n",
    "\n",
    "lr_test_preds = pickle.load(open('pickle/lr_test_preds', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_score = f1_score(y_train, lr_train_preds)\n",
    "lr_test_score = f1_score(y_test, lr_test_preds)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Training F1: {:.4} \\t\\t\".format(lr_train_score))\n",
    "print(\"Test F1: {:.4} \\t\\t\".format(lr_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model Review\n",
    "Great scores on both training and especially testing. I will move forward from here by using Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'solver': ['newton-cg'],\n",
    "          'penalty': ['l2', 'elasticnet'], \n",
    "          'tol': [0.5, 1.0, 2.0],\n",
    "          'C': [1.0, 2.0, 3.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid = params)\n",
    "grid.fit(tf_idf_data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_tuned = LogisticRegression(max_iter = 500, C = 3, penalty = 'l2', solver = 'newton-cg', tol = 1)\n",
    "lr_tuned.fit(tf_idf_data_train, y_train)\n",
    "lr_tuned_train_preds = lr_tuned.predict(tf_idf_data_train)\n",
    "lr_tuned_test_preds = lr_tuned.predict(tf_idf_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle tuned lr model and predictions\n",
    "\n",
    "filename = 'pickle/lr_classifier_tuned'\n",
    "pickle.dump(lr_tuned, open(filename, 'wb'))\n",
    "\n",
    "filename = 'pickle/lr_tuned_train_preds'\n",
    "pickle.dump(lr_tuned_train_preds, open(filename, 'wb'))\n",
    "\n",
    "filename = 'pickle/lr_tuned_test_preds'\n",
    "pickle.dump(lr_tuned_test_preds, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tuned lr pickle\n",
    "\n",
    "# load lr pickle\n",
    "\n",
    "lr_tuned_train_preds = pickle.load(open('pickle/lr_tuned_train_preds', 'rb'))\n",
    "\n",
    "lr_tuned_test_preds = pickle.load(open('pickle/lr_tuned_test_preds', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Logistic Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_train_score = f1_score(y_train, lr_tuned_train_preds)\n",
    "lr_test_score = f1_score(y_test, lr_tuned_test_preds)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Training F1: {:.4} \\t\\t\".format(lr_train_score))\n",
    "print(\"Test F1: {:.4} \\t\\t\".format(lr_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, slightly better results here after tuning the model. I ran through this grid search multiple times with different parameters (although it is not shown since I went back into the original parameter cell and altered it based on previous grid search results). I think this is a good enough tuned model to move forward with and test our neutral reviews on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on Manually Classified Neutrals\n",
    "Some deviations here from the presentation metrics because I added in more entries to the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = manual_test['text']\n",
    "y_val = manual_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_data_val = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline lr validation\n",
    "lr = pickle.load(open('pickle/lr_classifier', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_val_preds = lr.predict(tf_idf_data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_val_score = f1_score(y_val, lr_val_preds)\n",
    "\n",
    "print(\"Val F1: {:.4} \\t\\t\".format(lr_val_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuned LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned lr validation\n",
    "lr_tuned = pickle.load(open('pickle/lr_classifier_tuned', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tuned_val_preds = lr_tuned.predict(tf_idf_data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tuned_val_score = f1_score(y_val, lr_tuned_val_preds)\n",
    "\n",
    "print(\"Val F1: {:.4} \\t\\t\".format(lr_val_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically no difference between the original baseline Logistic Regression model and the tuned Logistic Regression model. Either way, the models are predicting correctly around 73% of the time. A large portion of this is probably because of how few entries we have in the Neutral Reviews validation dataset, so the tuning isn't being fully put to use here. However, we cannot say that with absolute certainty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion to all of this, we can see that generally speaking, Logistic Regression works the best for NLP. Of course, more neutral review data is needed for both training and validation, as adding just ~10 more entries to the validation data increased the F1 score by 5-6%. Also, the ability to separate between domains (restaurants, services, hotels, etc.) will give a huge boost to the usability of the model. \n",
    "\n",
    "##### Conclusion F1 Scores\n",
    ">\n",
    "> <b>Baseline Logistic Regression:</b>\n",
    ">\n",
    "> Training F1: 0.9739\n",
    ">\n",
    "> Test F1: 0.9697\n",
    "\n",
    "> <b>Tuned Logistic Regression:</b>\n",
    ">\n",
    "> Training F1: 0.978 \t\t\n",
    ">\n",
    "> Test F1: 0.9706 \n",
    "\n",
    "> <b>Neutral Review Validation (Neutral Reviews Only):</b>\n",
    ">\n",
    "> Val F1: 0.7342\n",
    "\n",
    "As of now, we have a model in which we can enter a text review, and retrieve a prediction as to whether that text review is positive or negative. However, there is not a complete business use for this until we can retrieve the predicted positive or negative as well as tokenized words to make it faster to gain insights from, which was the point of the project. Thus, I am working on deploying a webapp through Streamlit in which a user can enter the text of a reviews, and retrieve both the predicted positive or negative rating, and the tokenized words in the review, making for a quick way to gain insights. \n",
    "\n",
    "Below, I have an example of a Webapp I am in the progress of making. Hopefully, it can be finished and deployed soon. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlit Webapp (In Progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (1.11.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: blinker>=1.0.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (1.5)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (2.0.0)\n",
      "Requirement already satisfied: tzlocal>=1.1 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (4.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (3.20.1)\n",
      "Requirement already satisfied: pyarrow>=4.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (0.10.1)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (6.0.4)\n",
      "Requirement already satisfied: pympler>=0.9 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (1.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (2.8.1)\n",
      "Requirement already satisfied: altair>=3.2.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (4.2.0)\n",
      "Requirement already satisfied: validators>=0.2 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (0.20.0)\n",
      "Requirement already satisfied: watchdog; platform_system != \"Darwin\" in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (0.10.3)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (0.7.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (12.5.1)\n",
      "Requirement already satisfied: requests>=2.4 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (2.24.0)\n",
      "Requirement already satisfied: pandas>=0.21.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (1.1.3)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (3.1.27)\n",
      "Requirement already satisfied: attrs>=16.0.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (20.3.0)\n",
      "Requirement already satisfied: semver in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (2.13.0)\n",
      "Requirement already satisfied: packaging>=14.1 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (20.4)\n",
      "Requirement already satisfied: cachetools>=4.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (5.2.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (7.1.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (8.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from streamlit) (4.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->streamlit) (3.4.0)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from tzlocal>=1.1->streamlit) (0.1.0.post0)\n",
      "Requirement already satisfied: tzdata; platform_system == \"Windows\" in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from tzlocal>=1.1->streamlit) (2022.1)\n",
      "Requirement already satisfied: backports.zoneinfo; python_version < \"3.9\" in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from tzlocal>=1.1->streamlit) (0.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from python-dateutil->streamlit) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (2.11.2)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (3.2.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from validators>=0.2->streamlit) (4.4.2)\n",
      "Requirement already satisfied: pathtools>=0.1.1 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from watchdog; platform_system != \"Darwin\"->streamlit) (0.1.2)\n",
      "Requirement already satisfied: ipykernel>=5.1.2; python_version >= \"3.4\" in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (5.3.4)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (7.5.1)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from rich>=10.11.0->streamlit) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from rich>=10.11.0->streamlit) (2.7.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from pandas>=0.21.0->streamlit) (2020.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19->streamlit) (4.0.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from packaging>=14.1->streamlit) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.17.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (50.3.1.post20201107)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (7.19.0)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (6.1.7)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.0.8)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (5.0.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (3.0.8)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: backcall in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.17.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.6.3)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (19.0.2)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.1.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (227)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (20.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.1)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.0.7)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.14.3)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.7)\n",
      "Requirement already satisfied: bleach in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.2.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
      "Requirement already satisfied: testpath in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.20)\n",
      "Requirement already satisfied: webencodings in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Requirement already satisfied: async-generator in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\nehcr\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "#!pip install streamlit scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing lib: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5969a264e219>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#import joblib.os\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#import spacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\streamlit\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msource_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_source_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_string_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeltaGenerator\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_DeltaGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreport_thread\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_report_ctx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_add_report_ctx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreport_thread\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_report_ctx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_get_report_ctx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\streamlit\\delta_generator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcaching\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtype_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\streamlit\\caching.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_util\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhandle_uncaught_app_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStreamlitAPIWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhashing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mupdate_hash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHashFuncsDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhashing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHashReason\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_logger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\streamlit\\hashing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfile_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtype_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStreamlitAPIException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMarkdownFormattedException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\streamlit\\type_util.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pyarrow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_cpu_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m from pyarrow.lib import (null, bool_,\n\u001b[0;32m     51\u001b[0m                          \u001b[0mint8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing lib: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "#import joblib.os\n",
    "\n",
    "#import spacy\n",
    "\n",
    "def main():\n",
    "    '''Review Classifier App with Streamlit'''\n",
    "    st.title('Review Sentiment Classifier ML App')\n",
    "    \n",
    "#if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=bEOiYF1a6Ak\n",
    "\n",
    "import streamlit as st \n",
    "import joblib,os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "\n",
    "# Vectorizer\n",
    "review_vectorizer = open('pickle/tfidf_vectorizer', 'rb')\n",
    "review_cv = joblib.load(review_vectorizer)\n",
    "\n",
    "# Load Models\n",
    "def load_prediction_models(model_file):\n",
    "    loaded_models = joblib.load(open(os.path.join(model_file), 'rb'))\n",
    "    return loaded_models\n",
    "\n",
    "def get_keys(val, my_dict):\n",
    "    for key, value in my_dict.items():\n",
    "        if val == value: \n",
    "            return key\n",
    "\n",
    "# main classifier function\n",
    "def main():\n",
    "    '''Review Classifier App with Streamlit'''\n",
    "    st.title('Review Sentiment Classifier ML App')\n",
    "    st.subheader('NLP and ML App with Streamlit')\n",
    "    \n",
    "    activities = ['Prediction', 'NLP']\n",
    "    \n",
    "    choice = st.sidebar.selectbox('Choose Activity', activities)\n",
    "    \n",
    "    if choice == 'Prediction':\n",
    "        st.info('Prediction with ML')\n",
    "        \n",
    "        review_text = st.text_area('Enter Text', 'Type Here')\n",
    "        all_ml_models = ['Logistic Regression', 'NB']\n",
    "        model_choice = st.selectbox('Choose ML Model', all_ml_models)\n",
    "        prediction_labels = {'Negative': 0, 'Positive': 1}\n",
    "        if st.button('Classify'):\n",
    "            st.text('Original Test ::\\n{}'.format(review_text))\n",
    "            vect_text = review_cv.transform([review_text]).toarray()\n",
    "            if model_choice == 'LR': \n",
    "                predictor = load_prediction_models('pickle/lr_classifier_tuned')\n",
    "                prediction = predictor.predict(vect_text)\n",
    "                st.write(prediction)\n",
    "                final_result = get_keys(prediction, prediction_labels)\n",
    "                st.success(final_result)\n",
    "        \n",
    "        # 19:05 video timestamp\n",
    "        \n",
    "        \n",
    "    if choice == 'NLP':\n",
    "        st.info('Natural Language Processing')\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st \n",
    "import joblib,os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# load Vectorizer For Gender Prediction\n",
    "news_vectorizer = open(\"pickle/tfidf_vectorizer\",\"rb\")\n",
    "news_cv = joblib.load(news_vectorizer)\n",
    "\n",
    "def load_prediction_models(model_file):\n",
    "\tloaded_model = joblib.load(open(os.path.join(model_file),\"rb\"))\n",
    "\treturn loaded_model\n",
    "\n",
    "# Get the Keys\n",
    "def get_key(val,my_dict):\n",
    "\tfor key,value in my_dict.items():\n",
    "\t\tif val == value:\n",
    "\t\t\treturn key\n",
    "\n",
    "def main():\n",
    "\t\"\"\"Review Classifier\"\"\"\n",
    "\tst.title(\"Review Classifier\")\n",
    "\t# st.subheader(\"ML App with Streamlit\")\n",
    "\thtml_temp = \"\"\"\n",
    "\t<div style=\"background-color:blue;padding:10px\">\n",
    "\t<h1 style=\"color:white;text-align:center;\">Streamlit ML App </h1>\n",
    "\t</div>\n",
    "\t\"\"\"\n",
    "\tst.markdown(html_temp,unsafe_allow_html=True)\n",
    "\n",
    "\tactivity = ['Prediction','NLP']\n",
    "\tchoice = st.sidebar.selectbox(\"Select Activity\",activity)\n",
    "\n",
    "\n",
    "\tif choice == 'Prediction':\n",
    "\t\tst.info(\"Prediction with ML\")\n",
    "\n",
    "\t\tnews_text = st.text_area(\"Enter News Here\",\"Type Here\")\n",
    "\t\tall_ml_models = [\"LR\",\"NB\"]\n",
    "\t\tmodel_choice = st.selectbox(\"Select Model\",all_ml_models)\n",
    "\n",
    "\t\tprediction_labels = {'negative': 0,'positive': 1}\n",
    "\t\tif st.button(\"Classify\"):\n",
    "\t\t\tst.text(\"Original Text::\\n{}\".format(news_text))\n",
    "\t\t\tvect_text = news_cv.transform([news_text]).toarray()\n",
    "\t\t\tif model_choice == 'LR':\n",
    "\t\t\t\tpredictor = load_prediction_models(\"pickle/lr_classifier_tuned\")\n",
    "\t\t\t\tprediction = predictor.predict(vect_text)\n",
    "\t\t\t\t# st.write(prediction)\n",
    "\t\t\telif model_choice == 'NB':\n",
    "\t\t\t\tpredictor = load_prediction_models(\"pickle/nb_classifier\")\n",
    "\t\t\t\tprediction = predictor.predict(vect_text)\n",
    "\t\t\t\t# st.write(prediction)\n",
    "\t\t\tfinal_result = get_key(prediction,prediction_labels)\n",
    "\t\t\tst.success(\"Reviewgorized as:: {}\".format(final_result))\n",
    "\n",
    "\tif choice == 'NLP':\n",
    "\t\tst.info(\"Natural Language Processing of Text\")\n",
    "\t\traw_text = st.text_area(\"Enter News Here\",\"Type Here\")\n",
    "\t\tnlp_task = [\"Tokenization\",\"Lemmatization\",\"NER\",\"POS Tags\"]\n",
    "\t\ttask_choice = st.selectbox(\"Choose NLP Task\",nlp_task)\n",
    "\t\tif st.button(\"Analyze\"):\n",
    "\t\t\tst.info(\"Original Text::\\n{}\".format(raw_text))\n",
    "\n",
    "\t\t\tdocx = nlp(raw_text)\n",
    "\t\t\tif task_choice == 'Tokenization':\n",
    "\t\t\t\tresult = [token.text for token in docx ]\n",
    "\t\t\telif task_choice == 'Lemmatization':\n",
    "\t\t\t\tresult = [\"'Token':{},'Lemma':{}\".format(token.text,token.lemma_) for token in docx]\n",
    "\t\t\telif task_choice == 'NER':\n",
    "\t\t\t\tresult = [(entity.text,entity.label_)for entity in docx.ents]\n",
    "\t\t\telif task_choice == 'POS Tags':\n",
    "\t\t\t\tresult = [\"'Token':{},'POS':{},'Dependency':{}\".format(word.text,word.tag_,word.dep_) for word in docx]\n",
    "\n",
    "\t\t\tst.json(result)\n",
    "\n",
    "\t\tif st.button(\"Tabulize\"):\n",
    "\t\t\tdocx = nlp(raw_text)\n",
    "\t\t\tc_tokens = [token.text for token in docx ]\n",
    "\t\t\tc_lemma = [token.lemma_ for token in docx ]\n",
    "\t\t\tc_pos = [token.pos_ for token in docx ]\n",
    "\n",
    "\t\t\tnew_df = pd.DataFrame(zip(c_tokens,c_lemma,c_pos),columns=['Tokens','Lemma','POS'])\n",
    "\t\t\tst.dataframe(new_df)\n",
    "\n",
    "\n",
    "\t\tif st.checkbox(\"WordCloud\"):\n",
    "\t\t\tc_text = raw_text\n",
    "\t\t\twordcloud = WordCloud().generate(c_text)\n",
    "\t\t\tplt.imshow(wordcloud,interpolation='bilinear')\n",
    "\t\t\tplt.axis(\"off\")\n",
    "\t\t\tst.pyplot()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tst.sidebar.subheader(\"About\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
